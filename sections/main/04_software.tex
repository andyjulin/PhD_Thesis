\chapter{Analysis Software}
\label{ch:software}

\section{BESIII Offline Software System}

Reconstructing and processing event data gathered by the BESIII detector is done using the BESIII Offline Software System (BOSS) \cite{ref:Li:2006}.
This is an analysis software distribution written using the C++ language and running primarily on the Scientific Linux CERN operating system \cite{ref:SLC5}.
There are five main parts to BOSS: framework, simulation, reconstruction, calibration, and analysis.


\subsection{Framework}

The framework is built on the Gaudi software architecture \cite{ref:Barrand:2001}, which provides a standard interface and utilities for things such as event simulation, data processing, and physics analysis.
The software is managed using the Configuration Management Tool \cite{ref:Arnault:2000}, which provides a method for creating packages, handling package dependencies, and producing executables from source code.
There are three main filetypes for data stored by the framework: raw data ($\texttt{.raw}$), reconstructed data ($\texttt{.rec}$), and Data-Summary-Tape ($\texttt{.dst}$).
The latter two of these file types are derived from the ROOT \cite{ref:ROOT} format ($\texttt{.root}$) for easy management and usage in various analyses.


\subsection{Simulation}

There are four main parts to the simulation process: event generation, detector description, particle tracking, and detector response.
Event generation is primarily handled by the Monte Carlo (MC) generators KKMC, BesEvtGen, and Babayaga, which are described below.
To model its geometry and materials, a unique description of the detector has been created using a format based on XML.
This allows both simulation and reconstruction packages to appropriately model the behavior of events within the specific environment of BESIII.
For particle tracking, interactions with detector materials are handled by GEANT4 \cite{ref:Agostinelli:2003}.
Lastly, detector responses are modeled by the so-called `digitization code'.
This takes into account each detector component, as well as readout electronics, and realistic situations such as noise or dead channels.
There is also a simulation of the triggering system implemented.


\subsubsection{KKMC}

Originally developed for the LEP and SLC colliders, KKMC \cite{ref:Jadach:2000} is a generator used to model electroweak interactions.
Namely, the processes generated are of the form $\ee \rightarrow \ffbar + (n)\photon$, where $\fermion = \{ \mu, \tau, \qup, \qdown, \qstrange, \qcharm, \qbottom \}$, and $(n)\photon$ represents any number of additional photons.
These are modeled taking into account second-order sub-leading corrections, as well as initial-state radiation (ISR), and interference between initial- and final-state radiation (FSR).
The effects of beam energy spread, typically on the order of \SI{1}{\MeV} near the $\psipp$, can also be included.


After generation, the $\ffbar$ pair is decayed by models depending on the fermions involved.
The TAUOLA library \cite{ref:Jadach:1993} is used to decay $\tautau$ pairs, and takes into account spin-polarization effects.
The PYTHIA model \cite{ref:PYTHIA} is used to hadronize final-state $\qqbar$ continuum production using the parton shower model.
For resonances like the $\psipp$, the only action performed by KKMC is the generation of ISR.
After this, the virtual photon produced is handed off to BesEvtGen.


\subsubsection{BesEvtGen}

Originally developed for the CLEO and BaBar collaborations, EvtGen \cite{ref:Lange:2001} is another widely used generator.
It is the basis for BesEvtGen \cite{ref:Ping:2008}, which incorporates many different decay models into a single utility.
Over 30 exclusive decay models are available in BesEvtGen, as well as the capability to incorporate user-created models.


The simulation process occurs sequentially using dynamic information from decay amplitude probabilities and forward/backward spin-density matrices.
From this, final state radiation is handled by the PHOTOS model \cite{ref:Barberio:1991}.
To generate unknown decays of charmonium resonances, the LundCharm model \cite{ref:Chen:2000} is used, while other unknown hadronic decays are handled by PYTHIA.
For radiative processes, such as radiative return to $\jpsi$ or $\psip$, the VECTORISR model \cite{ref:Bonneau:1971} is used.
This occurs when one particle in the initial $\ee$ pair radiates a photon of high enough energy that only lower mass resonances can be produced from the reduced center-of-mass energy.
When the radiation is less energetic, the $\psipp$ resonance is directly produced through the combination of KKMC and BesEvtGen.


\subsubsection{Babayaga}

Production of QED processes is done using the Babayaga generator \cite{ref:Carloni:2004}.
This includes $\ee \rightarrow \{\ee, \mumu, \yy\}$.
The results are very accurate, with an estimated theoretical uncertainty of \SI{0.1}{\%}.
It also matches exact next-to-leading-order corrections from the parton shower algorithm.
The high precision is important for determination of the efficiencies and acceptances required to precisely measure the integrated luminosity.

\subsection{Reconstruction}

Reconstruction primarily involves information about specific types of particles from each of the four main detector subsystems.
These sources of information are as follows:
\begin{itemize}
    \item a charged track finding algorithm and a Kalman-filter-based track-fitter
    \item a particle identifying algorithm based on $\tdEdx$ and time-of-flight measurements
    \item a shower- and cluster-finding algorithm for EMC energy and position 
    \item a muon track finding algorithm
\end{itemize}
Further descriptions of each of these processes can be found in Sec. \ref{sec:detector_simulation}.
Additionally, algorithms for determining the corresponding beam bunch crossing, as well as for secondary vertex and track refitting, are also utilized.


\subsection{Calibration}

To maintain consistent production and analysis of datasets, a centralized source of run-dependent information is maintained by BOSS.
This includes algorithms which determine the calibration constants for each sub-detector, as well as a centralized database to store the results.
Each of the calibration outputs are stored in a ROOT file along with other details such as the beam energy, luminosity, magnetic field information, trigger conditions, and hardware/software versions.
While all of this information is stored by a central MySQL \cite{ref:MySQL} server at IHEP, other institutions in BESIII regularly synchronize with this server to create mirrored copies of these databases.



\section{Detector Simulation}
\label{sec:detector_simulation}

The following sections detail the simulation, calibration, and reconstruction processes for each detector subsystem.
Each of these relies on a geometry description created using GEANT4.


\subsection{Multi-Layer Drift Chamber}

Simulating events in the MDC accounts for axial layers, stereo layers, and endplates.
The simulation also relies on the calibration parameters to determine things such as wire efficiency and resolution as a function of drift distance for each wire, noise in each layer, and possible misalignment.


Calibration of the MDC relies on $\jpsi \rightarrow \mumu$ for both position and $\tdEdx$.
Using $\jpsi$ events allows for quickly obtaining sufficient statistics due to the very large production cross section at that peak.
The information determined includes constants such as $x-t$ relations, timing, alignment, and absolute wire efficiency.
These values are stored in the database for each run.
Special-purpose runs with the magnetic field turned off allow precise determination of wire positions.


Reconstructing MDC events starts by finding axial track segments using raw hits.
These are found by searching for matches to pre-determined patterns.
Next, these segments are fitted to circular tracks using the least-squares method.
Stereo segments are then added using an iterative helix fit.
Lastly, additional hits which were possibly missed from the initial reconstruction are added to the track using a Kalman-filter process.
This process determines the track parameters for multiple particle hypotheses.
The reconstruction is remarkably efficient, with over \SI{98}{\%} of tracks with $p_T > \SI{150}{\MeV}$ being reconstructed, even amidst high backgrounds.
From this, the charge, momentum, and trajectory can be determined for each track.


In addition to tracking, the MDC also measures the ionization energy deposited per unit length, $\tdEdx$, for each particle.
The energy deposition of each track as it passes through the chamber is compared to expectations to determine a probability for each particle hypothesis.
Corrections applied account for things such as multiple scatterings, magnetic deflection, and ionization.
This likelihood from $\tdEdx$ is combined with information from the ToF to determine the type of particle that best matches the track properties.


\subsection{Time-of-Flight System}

Simulating events in the ToF accounts for the scintillator, wrapping materials, and photomultiplier tubes (PMTs).
The process converts the energy deposited in the scintillator into photons, then propagates the shape of a photon pulse (rather than individual photons) to the PMTs in order to generate an electronic signal.
A discriminator is applied to each pulse to determine the analog-to-digital conversion (ADC) and time-to-digital conversion (TDC) outputs.
The algorithm was designed and tested with dedicated test beam data, however, each new data set requires updated tuning.
A full simulation tracing each optical photon is also available for detailed study of the timing measurements.


Calibration of the ToF also uses $\jpsi$ decays to dileptons for both timing and energy measurements.
The information determined includes effective velocity, attenuation length, and muon energy loss.
The status and performance of the ToF are regularly monitored by a laser-fiberoptics pulsing system.


Reconstructing ToF events starts by using tracks with trajectories extrapolated from the MDC.
Each track is matched with a particular ToF module; either the two layers of the barrel, or the single-layer endcap.
The travel time for each hypothesis is then calculated using weighted-average times from PMTs at both ends of the scintillator.
Corrections are also applied to account for aspects like the effective light velocity in the scintillator and the light attenuation length.
Measurements of deposited energy are obtained for both charged and neutral particles, and are added to the EMC to improve the shower energy resolution.


\subsection{Electromagnetic Calorimeter}

Simulating events in the EMC accounts for the crystals, casing, silicon photodiodes, preamplifier boxes, cables, and the support system.
For each of the crystals and photodiodes, hit information is recorded, and the deposited energy is summed.
From this, photon statistics are computed, and the resulting photodiode response is converted into electronic signals.
To obtain the waveform in the time domain, an inverse Laplace transform is applied.
Then, a sampling and peak searching process is simulated to yield energy and time information.
For each bin, Gaussian-type electronic noise is added, and the background is produced by summing over the waveforms.


Calibration of the EMC uses Bhabha electrons with $E > \SI{1.55}{\GeV}$ for the high energy response, and $\piO \rightarrow \yy$ decays for the low energy response.
The responses for individual crystals must be analyzed separately, due to their potential intrinsic variations.
As a result, they are monitored frequently by a LED light pulser, and periodically recalibrated.
Corrections due to temperature variations are also applied.


Reconstructing EMC events starts by converting the ADC value of each crystal into energy based on the calibration constants.
After this, clusters in both the barrel and endcaps are formed by analyzing local maximum energy deposits, called seeds.
A clustering algorithm then aggregates hits around these seeds and sums the values for a particular shower.
The position of each shower is then calculated using the energy-weighted first moment.
If multiple seeds are found in one cluster, a splitting algorithm is invoked to split the cluster into multiple showers.
Additionally, matching energy deposits from the ToF are also added back into the total shower energy.
This improves the energy resolution, particularly for low energy photons.


\subsection{Muon Identifier}

Simulating events in the MUC accounts for forming each RPC, creating sets of strips to form each read-out plane, combining each of these with aluminum boxes to form a muon counter module, and interleaving the modules between layers of iron plates.
The digitization from the read-out planes is selected to fire based on the distance to each track.
Noise is simulated using Poisson distributions initially determined from measurements made during the construction of the chamber, and updated during actual data taking.


Calibration of the MUC analyzes RPC detection efficiencies as function of area.
The cluster sizes and noise levels are also studied.


Reconstructing MUC events starts by searching for collected hits in each of the barrel and endcap orientations.
The two collections are then matched with reconstructed tracks from the MDC.
Since low momentum muons may cause only a few layers to fire, a subsequent search is performed over unused hits based on the extrapolated trajectories of MDC tracks.
The reconstruction process primarily analyzes the depth of the track in the MUC, the maximum number of hits in the layers fired by a track, and the matching between a MDC track with the MUC stand-alone track.
These parameters, along with the track momentum and MDC exit angle, are input into an Artificial Neural Network in order to distinguish between hadron and muon tracks.
The identification process is quite effective, generally removing \SI{\sim96}{\%} of pions and retaining \SI{\sim90}{\%} of muons.



\section{$D$-Tagging}
\label{sec:d_tagging}

From the decay of the $\psipp$, the most commonly produced particles are $\DO\aDO$ or $\Dp\Dm$ pairs.
Since the $\DDbar$ pairs are produced in two-body decays, the energy of each $\D$ is half of the center-of-mass energy (in the center-of-mass reference frame).
Each of these $\D$ mesons then quickly decays to certain sets of particles.
Reconstructing one of these decays requires assembling the right combination of such particles under the constraint of 4-momentum conservation.


This reconstruction technique is known as `$\D$-Tagging', and was pioneered by the MARK-III collaboration \cite{ref:Baltrusaitis:1986,ref:Adler:1988}.
For our analysis, the particles analyzed in the detector include $\pipm, \; \Kpm, \; \piO,$ and $\Ks$, and the decay modes used are shown in \Cref{tab:dtag_modes}.
There are three $\DO$ modes and six $\Dp$ modes, where charge conjugation (converting all particles to their anti-particles) is implied throughout the analysis.
The modes used are chosen for their overall efficiency of reconstruction in the detector; they generally have higher branching fractions and manageable multiplicity (the number of tracks in the final state).
For the neutral modes, this procedure also includes the doubly-Cabbibo suppressed decays (DCSD), such as $\DO \rightarrow \Kp \; \pim$, which have small and well-measured branching fractions.

\begin{table}[h]
\centering
\begin{tabular}{l|l l}
\hline
(0) $\DOmodeA$ & (200) $\DpmodeA$ & (203) $\DpmodeD$ \\
(1) $\DOmodeB$ & (201) $\DpmodeB$ & (204) $\DpmodeE$ \\
(3) $\DOmodeC$ & (202) $\DpmodeC$ & (205) $\DpmodeF$ \\
\hline
\end{tabular}
\caption{The reconstructed $\Dtag$ modes used in this analysis.}
{The numerical values are shorthand codes used by the reconstruction software.}
\label{tab:dtag_modes}
\end{table}

This process occurs for each event and searches over each decay mode for each charm state ($\Dp$ and $\Dm$).
The combinations chosen for reconstruction are those with the smallest energy difference from the expected value.
More than one $\D$ combination can be extracted from a given event, as long as it satisfies all other requirements (see \Cref{ssec:selection_cuts}).
While this may sound like it overestimates the number of actual $\D$ particles found, the process is also used to calculate reconstruction efficiency, thereby eliminating any bias.


\subsection{Selection Cuts}
\label{ssec:selection_cuts}

Before being considered as potential reconstruction candidates, each track in the detector must also pass other cuts specific to its identified particle type.
The following describes the criteria required for the particles in the decay modes we are using.


\subsubsection{$\pipm / \Kpm$ Selection}
\label{sssec:kpi_selection}

Each of the reconstructed charged tracks must pass vertex cuts in both the transverse ($x-y$) and beam ($z$) directions relative to the interaction point.
This requires that tracks originate sufficiently close to the interaction point to ensure they are not other backgrounds, such as cosmic rays, or daughters of tracks which have decayed in flight.
There is also a cut on the polar angle measured within the MDC ($\theta$) to ensure the track can reliably be reconstructed.
Lastly, from the particle identification process, the probability of being a pion (kaon) must be greater than that for being a kaon (pion).
The specific cuts for each of these requirements can be found in \Cref{tab:kpi_cuts}.

\begin{table}[h]
\centering
\begin{tabular}{c| r@{$\; < \;$}l }
\hline
Vertex ($xy$)    & $V_{xy}$ & \pp \SI{1}{\cm} \\
Vertex ($z$)     & $|Vz|$   & \SI{10}{\cm} \\
MDC Angle        & $|\cos\theta|$ & 0.93 \\
Pion Probability & \multicolumn{2}{c}{ $\pp P(\pi) > 0, \quad P(\pi) > P(K)$ } \\
Kaon Probability & \multicolumn{2}{c}{ $P(K)   > 0, \quad P(K) > P(\pi)$ } \\
\hline
\end{tabular}
\caption{The required cuts to identify charged tracks as $\pipm$ or $\Kpm$.}
{The first two cuts ensure each track originates near the collision vertex, while the third ensures the track does not disappear down the beam-pipe.
The final two cuts categorize the particle candidate, ensuring there is at least some likelihood to be the intended particle.}
\label{tab:kpi_cuts}
\end{table}


\subsubsection{$\photon$ Selection}
\label{sssec:photon_selection}

To distinguish photon energy from noise, each shower in the EMC is required to have a certain amount of deposited energy.
These cuts are different for the barrel ($|\cos\theta| < 0.80$) and endcap ($0.84 < |\cos\theta| < 0.92$) regions.
Each photon must also pass a timing cut to ensure they are consistent with actual physics events, and not originating at other times.
The values for each of these requirements can be found in \Cref{tab:photon_cuts}.

\begin{table}[h]
\centering
\begin{tabular}{c|c r}
\hline
Minimum Energy (Barrel) & $E_{\text{EMC}} > \SI{25}{\MeV}$ & $(|\cos\theta| < 0.80)$ \\
Minimum Energy (Endcap) & $E_{\text{EMC}} > \SI{50}{\MeV}$ & $(0.84 < |\cos\theta| < 0.92)$ \\
TDC Timing & $ (0 \leq t \leq 14) \times \SI{50}{\ns} $ \\ 
\hline
\end{tabular}
\caption{The required cuts to identify neutral showers as a $\photon$.}
{The first two cuts ensure the photon track is above background noise levels, while the third ensures the track came from the actual collision.}
\label{tab:photon_cuts}
\end{table}


\subsubsection{$\piO$ Selection}
\label{sssec:pi0_selection}

Reconstructing $\piO$ mesons involves finding $\yy$ pairs, as this the most dominant decay (\SI{\sim99}{\%}).
Each of the $\photon$ showers must pass the cuts described above. 
Additionally, at least one photon in the pair must be found in the barrel region.
Each of the two photons are then kinematically fitted to compare with the invariant mass of the $\piO$, and must also pass a proper fit cut.
The resulting momentum from this fit is used for reconstructing $\Dtag$ candidates.
The values used for each of these requirements are shown in \Cref{tab:pi0_cuts}.

\begin{table}[h]
\centering
\begin{tabular}{c|c}
\hline
Nominal Mass & $\SI{115}{\MeV} < m_{\piO} < \SI{150}{\MeV}$ \\
Fit Quality  & $\chi^2 < 200$, Converged \\
\hline
\end{tabular}
\caption{The required cuts to reconstruct $\yy$ pairs as a $\piO$.}
{The first cut ensures the reconstructed pair is consistent with a $\piO$, while the second ensures the vertex fitting procedure is properly applied.}
\label{tab:pi0_cuts}
\end{table}


\subsubsection{$\Ks$ Selection}
\label{sssec:ks_selection}

Reconstructing $\Ks$ mesons involves finding $\pip\pim$ pairs, as this is its most common decay (\SI{\sim70}{\%}).
While $\piO\piO$ pairs are also a substantial decay mode (\SI{\sim30}{\%}), these are not considered due to the difficulty of correctly reconstructing the $4\photon$ final state.
To account for the $\Ks$ decaying in flight, each of the charged pions considered are not subjected to the vertex or probability cuts in \Cref{tab:kpi_cuts}.
Instead, the two found pions are kinematically constrained to a common vertex.
The results must pass a nominal mass cut (\SI{\sim3}{\sigma}) and a proper fit cut to be deemed a $\Ks$.
From this, the resulting momentum from the vertex fit is used for reconstructing $\Dtag$ candidates.
The values used for each of these requirements are shown in \Cref{tab:ks_cuts}.

\begin{table}[h]
\centering
\begin{tabular}{c|c}
\hline
Nominal Mass & $\SI{487}{\MeV} < m_{\Ks} < \SI{511}{\MeV}$ \\
Fit Quality  & $\chi^2 < 100$, Converged \\
\hline
\end{tabular}
\caption{The required cuts to reconstruct $\pip\pim$ pairs as a $\Ks$.}
{The first cut ensures the reconstructed pair is consistent with a $\Ks$, while the second ensures the vertex fitting procedure is properly applied.}
\label{tab:ks_cuts}
\end{table}

\subsubsection{Cosmic Ray and Lepton Veto}
\label{sssec:cosmic_and_lepton}

When reconstructing the mode $\DOmodeA$, an additional veto is used.
Since this mode has only two charged tracks, it is common to misidentify particles which come from cosmic ray and backgrounds like $\ee \rightarrow \{\gamma\ee, \; \gamma\mumu\}$.
To prevent this, cuts on the timing difference between the tracks, as well as on the particle identification variables, are imposed.
The values used for these requirements are shown in \Cref{tab:veto_cuts}.

\begin{table}[h]
\centering
\begin{tabular}{c|c}
\hline
Timing (TDC) & $|t_1 - t_2| < 5 \times \SI{50}{\ns}$ \\
Particle Identification & $(\chi_{\lel}^2 + \chi_{\alel}^2) - (\chi_{\Km}^2 + \chi_{\pip}^2) > 10$ \\
\hline
\end{tabular}
\caption{Cuts to suppress cosmic ray and lepton backgrounds in $\DOmodeA$.}
{The first cut ensures the tracks are consistent with an actual collision event, while the second ensures the hypothesis is most likely to be the decay mode $\DOmodeA$.}
\label{tab:veto_cuts}
\end{table}


\subsection{Reconstruction}
\label{ssec:dtag_reconstruction}

After all of the constituent particles are identified, reconstructed $\D$ candidates are characterized by two main kinematic quantities:
\beq
\DeltaE = |\Ebeam - \Etag|, \qquad \qquad \mbc = \sqrt{\Ebeam^2 - |\ptag|^2}.
\eeq
These are the energy difference ($\DeltaE$) and the beam-constrained mass ($\mbc$), and effectively represent the energy and momentum of the $\Dtag$, respectively.
As the candidate with the smallest $\DeltaE$ for each decay mode in each event is selected, the values will peak near \SI{0}{\MeV}.
Distributions of $\mbc$ peak near the respective $D$ masses, $m_{\DO} = \SI{1.865}{\GeV}$ or $m_{\Dp} = \SI{1.870}{\GeV}$.
While invariant mass ($\minv = \sqrt{\Etag^2 - |\ptag|^2}$) is an alternative selection variable, $\mbc$ is preferred because the beam energy is more precisely known than the 4-momenta of the individual particles comprising the $D$ candidate.

